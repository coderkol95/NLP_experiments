{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-09-09T10:35:35.796222Z","iopub.status.busy":"2022-09-09T10:35:35.795723Z","iopub.status.idle":"2022-09-09T10:35:35.802324Z","shell.execute_reply":"2022-09-09T10:35:35.801004Z","shell.execute_reply.started":"2022-09-09T10:35:35.796185Z"}},"source":["# Init"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-12T08:58:41.937002Z","iopub.status.busy":"2022-09-12T08:58:41.936051Z","iopub.status.idle":"2022-09-12T08:58:50.260789Z","shell.execute_reply":"2022-09-12T08:58:50.259721Z","shell.execute_reply.started":"2022-09-12T08:58:41.936960Z"},"trusted":true},"outputs":[],"source":["import pytorch_lightning as pl\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import glob\n","import re\n","from nltk.tokenize import RegexpTokenizer\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["# Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:58:50.262802Z","iopub.status.busy":"2022-09-12T08:58:50.262430Z","iopub.status.idle":"2022-09-12T08:58:50.269798Z","shell.execute_reply":"2022-09-12T08:58:50.268746Z","shell.execute_reply.started":"2022-09-12T08:58:50.262766Z"},"trusted":true},"outputs":[],"source":["topics = glob.glob('../0.Data/poemsdataset/topics/*')\n","topics = [re.sub('../input/poemsdataset/topics/','',x) for x in topics]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:58:50.273313Z","iopub.status.busy":"2022-09-12T08:58:50.272594Z","iopub.status.idle":"2022-09-12T08:59:28.449577Z","shell.execute_reply":"2022-09-12T08:59:28.448617Z","shell.execute_reply.started":"2022-09-12T08:58:50.273277Z"},"trusted":true},"outputs":[],"source":["poems = pd.DataFrame(columns=['poem','topic'])\n","\n","for topic in topics:\n","    path = glob.glob(f'../input/poemsdataset/topics/{topics[0]}/*')\n","    \n","    for p in path:\n","        with open(p,'r') as file:\n","            poem = file.read()\n","        poems.loc[len(poems.index)] = [poem, topic]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:59:28.451180Z","iopub.status.busy":"2022-09-12T08:59:28.450833Z","iopub.status.idle":"2022-09-12T08:59:28.460511Z","shell.execute_reply":"2022-09-12T08:59:28.459596Z","shell.execute_reply.started":"2022-09-12T08:59:28.451146Z"},"trusted":true},"outputs":[],"source":["poems = poems.sample(frac=1)\n","# poems.to_csv('poems.csv')\n","# poems = pd.read_csv('poems.csv')\n","# poems.drop(['Unnamed: 0'],axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:59:28.462509Z","iopub.status.busy":"2022-09-12T08:59:28.461877Z","iopub.status.idle":"2022-09-12T08:59:29.528238Z","shell.execute_reply":"2022-09-12T08:59:29.527253Z","shell.execute_reply.started":"2022-09-12T08:59:28.462473Z"},"trusted":true},"outputs":[],"source":["tokenizer = RegexpTokenizer(pattern='\\w+')\n","\n","def tokenizer_func(x):\n","    return tokenizer.tokenize(x.lower())\n","\n","poems['poem'] = poems['poem'].apply(tokenizer_func)\n","poems['poem'] = poems['poem'].apply(lambda x : [y.lower() for y in x])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:59:29.530215Z","iopub.status.busy":"2022-09-12T08:59:29.529837Z","iopub.status.idle":"2022-09-12T08:59:29.546255Z","shell.execute_reply":"2022-09-12T08:59:29.545183Z","shell.execute_reply.started":"2022-09-12T08:59:29.530178Z"},"trusted":true},"outputs":[],"source":["np.percentile(np.array([len(x) for x in poems.poem.values]), 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:59:29.548758Z","iopub.status.busy":"2022-09-12T08:59:29.547725Z","iopub.status.idle":"2022-09-12T08:59:29.624301Z","shell.execute_reply":"2022-09-12T08:59:29.623298Z","shell.execute_reply.started":"2022-09-12T08:59:29.548721Z"},"trusted":true},"outputs":[],"source":["def pad_sequences(text):\n","    \n","    if len(text) <= 105:\n","        text.extend(['']*(105 - len(text)))\n","        \n","    else:\n","        text = text[:105]\n","        \n","    return text\n","\n","poems['poem'] = poems['poem'].apply(pad_sequences)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T08:59:29.626408Z","iopub.status.busy":"2022-09-12T08:59:29.626028Z","iopub.status.idle":"2022-09-12T08:59:30.073503Z","shell.execute_reply":"2022-09-12T08:59:30.072505Z","shell.execute_reply.started":"2022-09-12T08:59:29.626369Z"},"trusted":true},"outputs":[],"source":["topics = poems['topic'].unique().tolist()\n","topics = dict(zip(topics,np.arange(len(topics))))\n","\n","poems['topic'] = poems['topic'].map(topics)\n","\n","words=[]\n","for poem in poems['poem']:\n","    words.extend(poem)\n","    \n","words = set(words)\n","\n","dictionary = defaultdict(default_factory=-1)\n","dictionary.update(zip(words,np.arange(len(words))))\n","    \n","poems_embedded=[]\n","\n","for i in np.arange(poems.shape[0]):\n","    poems_embedded.append([dictionary[x] for x in poems.loc[i,'poem']])\n","    \n","poems['poems_embedded'] = poems_embedded"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:40:57.744009Z","iopub.status.busy":"2022-09-12T09:40:57.743609Z","iopub.status.idle":"2022-09-12T09:40:57.761545Z","shell.execute_reply":"2022-09-12T09:40:57.759972Z","shell.execute_reply.started":"2022-09-12T09:40:57.743970Z"},"trusted":true},"outputs":[],"source":["class datamod(pl.LightningDataModule):\n","    \n","    def setup(self,stage):\n","            \n","        train_indices = np.random.choice(poems.index.tolist(), int(0.8 * poems.shape[0]))\n","        remaining_indices = list(set(poems.index.tolist()).difference(set(train_indices)))\n","        val_indices = np.random.choice(remaining_indices, int(0.1 * poems.shape[0]))\n","        test_indices = list(set(remaining_indices).difference(set(val_indices)))\n","        \n","        ## VERY IMPORTANT : IF 0 IS NOT IN INDEX, TORCH.TENSOR() AND TORCH.FROM_NUMPY() DOESN'T WORK\n","        \n","        train_indices = np.append(train_indices, 0) if 0 not in train_indices else train_indices\n","        val_indices = np.append(val_indices, 0) if 0 not in val_indices else val_indices\n","        test_indices = np.append(test_indices, 0) if 0 not in test_indices else test_indices\n","        \n","        self.poems = poems\n","        \n","        self.X_train = self.poems.loc[train_indices, 'poems_embedded']\n","        self.X_val = self.poems.loc[val_indices, 'poems_embedded']\n","        self.X_test = self.poems.loc[test_indices, 'poems_embedded']\n","        \n","        \n","        ## VERY IMPORTANT : CONVERTING A SERIES INTO A DF TO MAKE IT 2D AND HENCE INTO A NP ARRAY\n","        \n","        self.X_train = pd.DataFrame(self.X_train.tolist(), columns = np.arange(105)).values\n","        self.X_val = pd.DataFrame(self.X_val.tolist(), columns = np.arange(105)).values\n","        self.X_test = pd.DataFrame(self.X_test.tolist(), columns = np.arange(105)).values\n","        \n","        self.y_train = self.poems.loc[train_indices, 'topic']\n","        self.y_val = self.poems.loc[val_indices, 'topic']\n","        self.y_test = self.poems.loc[test_indices, 'topic']\n","        \n","        self.train_dataset = torch.utils.data.TensorDataset(torch.Tensor(self.X_train), torch.Tensor(self.y_train).reshape(-1,1))\n","        self.val_dataset = torch.utils.data.TensorDataset(torch.Tensor(self.X_val), torch.Tensor(self.y_val).reshape(-1,1))\n","        self.test_dataset = torch.utils.data.TensorDataset(torch.Tensor(self.X_test), torch.Tensor(self.y_test).reshape(-1,1))\n","    \n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(self.train_dataset, batch_size=32)\n","    \n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(self.val_dataset, batch_size=32)\n","    \n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(self.test_dataset, batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:43:14.211473Z","iopub.status.busy":"2022-09-12T09:43:14.211091Z","iopub.status.idle":"2022-09-12T09:43:14.226943Z","shell.execute_reply":"2022-09-12T09:43:14.225845Z","shell.execute_reply.started":"2022-09-12T09:43:14.211437Z"},"trusted":true},"outputs":[],"source":["class poem_classifier(pl.LightningModule):\n","    \n","    def __init__(self):\n","        \n","        super().__init__()\n","        \n","        self.embedding = torch.nn.Embedding(num_embeddings=len(list(dictionary.keys())), embedding_dim=64)\n","        self.lstm = torch.nn.LSTM(input_size = 64, hidden_size=64, num_layers = 2, batch_first=True)\n","        self.fc1 = torch.nn.Linear(in_features=64, out_features=128)\n","        self.fc2 = torch.nn.Linear(in_features=128, out_features=128)\n","        self.fc3 = torch.nn.Linear(in_features=128, out_features=64)\n","        self.fc4 = torch.nn.Linear(in_features=64, out_features=32)\n","        self.fc5 = torch.nn.Linear(in_features=32, out_features=16)\n","        self.fc6 = torch.nn.Linear(in_features=16, out_features=1)\n","        \n","    def forward(self, x):\n","        \n","        x = self.embedding(x)\n","        x, _ = self.lstm(x)\n","        x = x[:,-1,:]\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.relu(self.fc3(x))\n","        x = torch.relu(self.fc4(x))\n","        x = torch.relu(self.fc5(x))\n","        x = torch.relu(self.fc6(x))\n","        \n","        return x\n","    \n","    def training_step(self, train_batch, batch_idx):\n","        \n","        X, y = train_batch\n","        logits = self.forward(X.long())\n","        loss = torch.nn.CrossEntropyLoss()\n","        train_loss = loss(y, logits)\n","        self.log('train_loss', train_loss, logger=True, prog_bar=True)\n","        return train_loss\n","    \n","    def validation_step(self, val_batch, batch_idx):\n","        \n","        X, y = val_batch\n","        logits = self.forward(X.long())\n","        loss = torch.nn.CrossEntropyLoss()\n","        val_loss = loss(y, logits)\n","        self.log('val_loss',val_loss, logger=True, prog_bar=True)\n","        \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:43:14.718309Z","iopub.status.busy":"2022-09-12T09:43:14.717710Z","iopub.status.idle":"2022-09-12T09:43:14.723641Z","shell.execute_reply":"2022-09-12T09:43:14.722633Z","shell.execute_reply.started":"2022-09-12T09:43:14.718274Z"},"trusted":true},"outputs":[],"source":["from pytorch_lightning.loggers import TensorBoardLogger\n","logger = TensorBoardLogger(\"lightning_logs\", name='poem-classification')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:45:05.425395Z","iopub.status.busy":"2022-09-12T09:45:05.424737Z","iopub.status.idle":"2022-09-12T09:50:23.032889Z","shell.execute_reply":"2022-09-12T09:50:23.031959Z","shell.execute_reply.started":"2022-09-12T09:45:05.425352Z"},"trusted":true},"outputs":[],"source":["data = datamod()\n","model = poem_classifier()\n","\n","trainer = pl.Trainer(max_epochs=50, accelerator='gpu', logger=logger)\n","\n","trainer.fit(model, data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:34:53.396598Z","iopub.status.busy":"2022-09-12T09:34:53.395463Z","iopub.status.idle":"2022-09-12T09:34:53.406956Z","shell.execute_reply":"2022-09-12T09:34:53.405783Z","shell.execute_reply.started":"2022-09-12T09:34:53.396544Z"},"trusted":true},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:35:02.532000Z","iopub.status.busy":"2022-09-12T09:35:02.531287Z","iopub.status.idle":"2022-09-12T09:35:03.577995Z","shell.execute_reply":"2022-09-12T09:35:03.576627Z","shell.execute_reply.started":"2022-09-12T09:35:02.531963Z"},"trusted":true},"outputs":[],"source":["rm -rf ./logs/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-12T09:50:23.035704Z","iopub.status.busy":"2022-09-12T09:50:23.035057Z","iopub.status.idle":"2022-09-12T09:50:26.118369Z","shell.execute_reply":"2022-09-12T09:50:26.117244Z","shell.execute_reply.started":"2022-09-12T09:50:23.035648Z"},"trusted":true},"outputs":[],"source":["%tensorboard --logdir ./lightning_logs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.12 ('pytorch_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"vscode":{"interpreter":{"hash":"57d879c1bab31ddce3f98747a90aac1ecdf0d747d4f9b6f921c92f41b19b21c9"}}},"nbformat":4,"nbformat_minor":4}
